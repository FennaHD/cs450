{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Segmentation\n",
    "\n",
    "### What to Submit\n",
    "Submit this iPython Notebook--containing all your code for the programming exercises below--on [learning suite](https://learningsuite.byu.edu/).\n",
    "\n",
    "Your notebook file should produce the relevant plots and also provide a short write-up with answers to the questions below.\n",
    "\n",
    "Please also fill in here the time that each part took you:\n",
    "* 1. Setting up PyMaxFlow: <span style=\"color:red;\">FILL IN TIME</span>\n",
    "* 2. Getting your first successful segmentation: <span style=\"color:red;\">FILL IN TIME</span>\n",
    "* 3. Adjusting parameters (e.g. $\\lambda$, $\\sigma$) and so forth, to get good results: <span style=\"color:red;\">FILL IN TIME</span>\n",
    "* 4. Completing the write-up: <span style=\"color:red;\">FILL IN TIME</span>\n",
    "\n",
    "Note that there are two folders within the project.  We have provided some images for you to use in testing your implementation, in the `provided images` folder along with their ground-truth segmentations to compare your results to.  Along with these, we want you to provide 2-4 additional images that you select on which you show your results.  <i>Please use the `provided_images` in that path and place any others in the `user_data` folder, and load all of the images (or user input point location files) via the approapriate relative path.  We will drop your notebook file and your `user_data` folder into our folder (which will have the `provided_images` already) and then run your notebook.</i>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Preparation:\n",
    "So that you can focus on the elements of the cost function ( the link weights), you may use a existing implementation of the actual min-cut algorithm itself.  You set up the graph, but it will take care of finding the minimum cut.\n",
    "\n",
    "For this assignment we will be using a python library called PyMaxFlow.  This library is a python wrapper around the original C++ implementation of the min-cut code from [Vladimir Kolmogorov](http://pub.ist.ac.at/%7Evnk/software.html) (who has co-authored several papers on this subject).    \n",
    "\n",
    "Note: For windows users, you will need the Visual C++ compiler in order for PyMaxFlow to work.  If you already have Visual Studio, this shouldn't be a problem but if you just want the compiler without Visual Studio, you can download [Build Tools For Visual Studio 2017](https://visualstudio.microsoft.com/downloads/#build-tools-for-visual-studio-2017). Once you have access to the Visual C++ compiler look at the next paragraph for PyMaxFlow installation.\n",
    "\n",
    "PyMaxFlow requires Cython, which should come standard in your anaconda environment but the command to install that will also be included.  To install PyMaxFlow enter the following commands replacing \"YourEnvironmentName\" with the name of your anaconda environment.\n",
    "~~~\n",
    "conda activate YourEnvironemntName\n",
    "conda install cython\n",
    "pip install pymaxflow\n",
    "~~~\n",
    "Once PyMaxFlow is installed, to understand how to use the library, there is a great [tutorial page](http://pmneila.github.io/PyMaxflow/tutorial.html) that shows how to get started with some simple examples.  Do the \"first example\" and perhaps the \"binary image restoration\" as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import maxflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Annotations:\n",
    "Graph cut segmentation is an interactive algorithm requiring the user to provide foreground and background seeds.  Provided is a python file that will open a gui and allow you to annotate the image.  This gui is optional and will require additional packages to be installed into your environment.  To install the packages open a terminal and enter the following commands:\n",
    "~~~\n",
    "conda activate YourEnvironmentName\n",
    "conda install scikit-image pillow\n",
    "~~~\n",
    "You can use the gui in the following way:\n",
    "```python\n",
    "import guiseg\n",
    "fore, back = guiseg.get_fore_back(image)\n",
    "image[fore]  # the foreground seeds\n",
    "image[back]  # the background seeds\n",
    "```\n",
    "\n",
    "For the `guiseg` routine to run, I also found it necssary to install PIL ImageTk (For me, it was `sudo apt install python3-pil.imagetk` but it will be different for Conda)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import guiseg\n",
    "\n",
    "import cv2\n",
    "#imageBGR = cv2.imread('provided_images/simplecircle.png');\n",
    "imageBGR = cv2.imread('provided_images/banana.png');\n",
    "image = imageBGR[:,:,::-1]; # I reverse the BGR from OpenCV to BGR\n",
    "\n",
    "# When the GUI pops up, you can pick either the \"Foreground\" or \"Background\" buttons to\n",
    "# select pixels to be respective seeds.  Once you're finished, click \"Return\"\n",
    "fore, back = guiseg.get_fore_back(image)\n",
    "print(image[fore][:5])  # foreground seeds (RGB values for all pixels drawn on, but only showing 5)\n",
    "print(image[back][:5])  # background seeds (RGB values for all pixels drawn on, but only showing 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Graph Cut:\n",
    "Your code should read in an image and a set of seed pixels and use graph-cut segmentation to segment the image.\n",
    "\n",
    "You will need to calculate the costs for the t-links (region terms) and the n-links (boundary terms). See the book, the notes/slides, or published papers in this area for ideas of how to define these.  Remember that the t-link weights to a particular terminal (foreground or background) should be large if that pixel looks a lot like the respective foreground/background seeds. The n-link weights should be large if the two neighboring pixels are similar.\n",
    "\n",
    "Here is [the original paper on graph-cut segmentation](http://www.csd.uwo.ca/~yuri/Papers/iccv01.pdf), which might help with some ideas, but you should look at the literature to see what other costs functions / link weights others have used.\n",
    "\n",
    "Once the graph is built, use the min-cut algorithm to partition the graph into nodes connected to the foreground node or to the background node, then use these as the resulting labels for the segmentation. Display this result graphically in some fashion overlaid on the input image.  It is best to start with simple images whose foreground and background colors are pretty different and for ones where the edges are pretty clear.  Graph-cut segmentation struggles sometimes with long, thin structures, so you should avoid these types of images early on.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Implementation Here (feel free to add additional cells of course)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate results Here (again, add additional cells to your heart's content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Grading / Rubric\n",
    "Points for this assigment will be assigned as follows (100 points total):\n",
    "* [20 pts] Code that correctly generates the graph network structure (nodes, n-links, t-links).\n",
    "* [10 pts] Code that produces the boundary term $B(p,q)$ used for n-links.\n",
    "* [10 pts] Code that produces the region term of the cost $R(p,A)$ used for the t-links.  Remember that you have t-links per pixel, one with cost determined by matching $p$ with the foreground appearance distribution, the other determined relative to the background distribution.  You may use the [sk-learn implementation](https://scikit-learn.org/stable/modules/density.html#kernel-density-estimation) of Kernel Density Estimation.  However you will receive 10 extra points if you implement it yourself.\n",
    "* [20 pts] Implementing the graph-cut with `pymaxflow` and finding the optimal solution for the input graph.\n",
    "* [10 pts] Displaying Results in the following format (for each input image you'll show the following 3-4 result images):\n",
    "   1. Original Image.\n",
    "   2. Tri-map of what was selected by the user (white for foreground, black for background, gray for unknown).  This can be overlaid on top of a faint copy of the image for context if desired.\n",
    "   3. Final segmentation.  Again you can overlay it on a faint copy of the original for context.\n",
    "   4. On the <i>provided images</i> please show a comparison of your resulting segmentaiton with the ground truth.\n",
    "* [20 pts] Good (certainly not perfect, some of them are challenging, but decent/reasonable) results on the 4 provided images (banana, llama, penguin, teddy).  Each image will receive up to 5 points.\n",
    "* [10 pts] Demonstrating your algorithm on 2-4 additional images.  At least one of the images should be somewhat easy, one should be somewhat challenging -- expalin why you think they're respectively easy/challenging.\n",
    "\n",
    "\n",
    "## Write-up:\n",
    "Provide an explanation for the following items:\n",
    "* Describe how you determinied/computed the n-link and t-link weights.\n",
    "* What kinds of image does graph cut segmentation work well for? What kinds of images do you find it struggles with?\n",
    "* What did you learn from the project?\n",
    "* What if any suggestions do you have for improving it (for future students)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red;\">WRITE-UP HERE</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
